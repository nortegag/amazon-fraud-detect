{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFxPD_JqEJMP"
   },
   "source": [
    "# SI 671 - Amazon Review Fraud Detection Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPzrBUgyEOpG"
   },
   "source": [
    "# Notebook 1: Preliminary Analysis\n",
    "Notebook Intent: Examination of the dataset's native characteristics, prior to major efforts in feature expansion. This is to help figure out what the state of class and categorical balances look like and, with only native features, see if there are any significant native differentiators between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjOrvfOqFXMX"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U9OzyksLEHIA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ArFeQmFTEh9t",
    "outputId": "3fce4653-5a66-440e-db22-cb95c5dae523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "qjVSzNrgEh_3",
    "outputId": "5a8b7c38-cf7b-4369-e7b3-ee78050a3a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000 records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>LEGIT</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VERIFIED_PURCHASE</th>\n",
       "      <th>PRODUCT_CATEGORY</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_TITLE</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>REVIEW_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>PC</td>\n",
       "      <td>B00008NG7N</td>\n",
       "      <td>Targus PAUK10U Ultra Mini USB Keypad, Black</td>\n",
       "      <td>useful</td>\n",
       "      <td>When least you think so, this product will sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>Wireless</td>\n",
       "      <td>B00LH0Y3NM</td>\n",
       "      <td>Note 3 Battery : Stalion Strength Replacement ...</td>\n",
       "      <td>New era for batteries</td>\n",
       "      <td>Lithium batteries are something new introduced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Baby</td>\n",
       "      <td>B000I5UZ1Q</td>\n",
       "      <td>Fisher-Price Papasan Cradle Swing, Starlight</td>\n",
       "      <td>doesn't swing very well.</td>\n",
       "      <td>I purchased this swing for my baby. She is 6 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>B003822IRA</td>\n",
       "      <td>Casio MS-80B Standard Function Desktop Calculator</td>\n",
       "      <td>Great computing!</td>\n",
       "      <td>I was looking for an inexpensive desk calcolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>B00PWSAXAM</td>\n",
       "      <td>Shine Whitening - Zero Peroxide Teeth Whitenin...</td>\n",
       "      <td>Only use twice a week</td>\n",
       "      <td>I only use it twice a week and the results are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOC_ID  ...                                        REVIEW_TEXT\n",
       "0       1  ...  When least you think so, this product will sav...\n",
       "1       2  ...  Lithium batteries are something new introduced...\n",
       "2       3  ...  I purchased this swing for my baby. She is 6 m...\n",
       "3       4  ...  I was looking for an inexpensive desk calcolat...\n",
       "4       5  ...  I only use it twice a week and the results are...\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"data/amazon_reviews.txt\", sep=\"\\t\")\n",
    "df = pd.read_csv('drive/Shared drives/SI671 Project [Data Mining]/data/amazon_reviews.txt', sep='\\t') \n",
    "print(f\"{df.shape[0]} records\")\n",
    "\n",
    "#### __label1__ means fraudulent while __label2__ means legitimate\n",
    "if('LABEL' in df.columns):\n",
    "    df.LABEL = df.LABEL.replace(to_replace='__label1__', value=0).replace('__label2__', value=1)\n",
    "    df = df.rename(columns={'LABEL':'LEGIT'})\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWnbVoAyFbfE"
   },
   "source": [
    "## Dataset Structural Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6FBvBEpTExNm",
    "outputId": "f243b59c-7fac-434f-d7bf-22776c36b161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a 50-50 split between legit and fake reviews\n",
      ".... 10500 Fraudulent and 10500 Legit\n",
      "\n",
      "No missing features in any records // dropna() doesn't change shape:\n",
      "(21000, 9), (21000, 9)\n",
      "\n",
      "We have 30 categories, each with 700 items:\n",
      "Sports                    700\n",
      "Toys                      700\n",
      "Apparel                   700\n",
      "Health & Personal Care    700\n",
      "Jewelry                   700\n",
      "Name: PRODUCT_CATEGORY, dtype: int64 \n",
      "\n",
      "When we subdivide category by legit-illegit counts, we can see each is split 50-50:\n",
      "PRODUCT_CATEGORY  LEGIT\n",
      "Apparel           0        350\n",
      "                  1        350\n",
      "Automotive        0        350\n",
      "                  1        350\n",
      "Baby              0        350\n",
      "                  1        350\n",
      "Name: LEGIT, dtype: int64 \n",
      "\n",
      "We also have a \"Verified Purchase\" field. More records in the dataset are verified than not.\n",
      "Being verified does not mean non-fraudulent:\n",
      "\t2877 Verified and Fraudulent\n",
      "\t8821 Verified Legitimate\n",
      "\t7623 Unverified and Fraudulent\n",
      "\t1679 Unverified Legitimate\n"
     ]
    }
   ],
   "source": [
    "print(\"We have a 50-50 split between legit and fake reviews\")\n",
    "print(f\".... {df.LEGIT.value_counts()[0]} Fraudulent and {df.LEGIT.value_counts()[1]} Legit\\n\")\n",
    "\n",
    "print(\"No missing features in any records // dropna() doesn't change shape:\")\n",
    "print(f\"{df.shape}, {df.dropna().shape}\\n\")\n",
    "\n",
    "print(f\"We have {df.PRODUCT_CATEGORY.describe()['unique']} categories, each with 700 items:\")\n",
    "print(df.PRODUCT_CATEGORY.value_counts()[:5],'\\n')\n",
    "\n",
    "print(f\"When we subdivide category by legit-illegit counts, we can see each is split 50-50:\")\n",
    "print(df.groupby('PRODUCT_CATEGORY').LEGIT.value_counts()[:6],'\\n')\n",
    "\n",
    "print(\"We also have a \\\"Verified Purchase\\\" field. More records in the dataset are verified than not.\")\n",
    "print(\"Being verified does not mean non-fraudulent:\")\n",
    "\n",
    "VerifLegitCounts = df.groupby('VERIFIED_PURCHASE').LEGIT.value_counts()\n",
    "print(f\"\\t{VerifLegitCounts.Y[0]} Verified and Fraudulent\\n\\t{VerifLegitCounts.Y[1]} Verified Legitimate\")\n",
    "print(f\"\\t{VerifLegitCounts.N[0]} Unverified and Fraudulent\\n\\t{VerifLegitCounts.N[1]} Unverified Legitimate\")\n",
    "\n",
    "# Verified Legitimacy-Fraudulancy Ratio Varies by Product Category\n",
    "# df.groupby(['LEGIT','PRODUCT_CATEGORY']).VERIFIED_PURCHASE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLVzBe3MRYzj",
    "outputId": "796fb765-90eb-401e-c3cb-0612fd92b9f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean, STDev, and quartiles for reviews are seemingly relatively non-significantly differentiated\n",
      "         count      mean       std  min  25%  50%  75%  max\n",
      "LEGIT                                                      \n",
      "0      10500.0  4.115429  1.285663  1.0  4.0  5.0  5.0  5.0\n",
      "1      10500.0  4.140476  1.270898  1.0  4.0  5.0  5.0  5.0 \n",
      "\n",
      "RATING    1    2    3     4     5\n",
      "LEGIT                            \n",
      "0       889  627  926  1999  6059\n",
      "1       868  565  942  1974  6151\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean, STDev, and quartiles for reviews are seemingly relatively non-significantly differentiated\")\n",
    "print(df.groupby('LEGIT').RATING.describe(),'\\n')\n",
    "print(df.groupby('LEGIT').RATING.value_counts().unstack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPPdSV-Cnb5Z"
   },
   "source": [
    "***\n",
    "## Comparing Stemmer and Lemmer for POS Preservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJytzVTWnkSV"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3O5QHB6nmpP",
    "outputId": "0db57f18-483c-4d50-fa5a-b902655c4a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet') \n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger') #POS Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "De7PSqNMWjo4",
    "outputId": "58a9c6d2-0250-45f6-fea4-7e7f22a8fbea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A burnt toasted enchillada I found under nick's car while i was running with you and him at his place after my dinner\n",
      "a burnt toasted enchillada i found under nick's car while i was running with you and him at his place after my dinn\n",
      "A burnt toasted enchillada I found under nick's car while i was running with you and him at his place after my dinner\n",
      "\n",
      "['A', 'bur', 'toa', 'enc', 'I', 'fou', 'und', 'nic', 'car', 'whi', 'i', 'was', 'run', 'wit', 'you', 'and', 'him', 'at', 'his', 'pla', 'aft', 'my', 'din']\n",
      "['DT', 'NN', 'VBD', 'NN', 'PRP', 'VBD', 'IN', 'JJ', 'NN', 'IN', 'NN', 'VBD', 'VBG', 'IN', 'PRP', 'CC', 'PRP', 'IN', 'PRP$', 'NN', 'IN', 'PRP$', 'NN']\n",
      "['DT', 'NN', 'VBD', 'NN', 'NN', 'VBD', 'IN', 'JJ', 'NN', 'IN', 'NN', 'VBD', 'VBG', 'IN', 'PRP', 'CC', 'PRP', 'IN', 'PRP$', 'NN', 'IN', 'PRP$', 'NN']\n",
      "['DT', 'NN', 'VBD', 'NN', 'PRP', 'VBD', 'IN', 'JJ', 'NN', 'IN', 'NN', 'VBD', 'VBG', 'IN', 'PRP', 'CC', 'PRP', 'IN', 'PRP$', 'NN', 'IN', 'PRP$', 'NN']\n"
     ]
    }
   ],
   "source": [
    " #### Comparison :: POS Tagging under vanilla, stemmed, and lemmed string variants\n",
    "sample_terms = ['A','burnt','toasted','enchillada','I','found','under',\"nick's\",'car',\n",
    "              'while','i','was','running','with','you','and','him','at','his','place',\n",
    "              'after','my','dinner']\n",
    "\n",
    "sample_str = ' '.join(sample_terms)\n",
    "stemmed_str = PorterStemmer().stem(sample_str)\n",
    "lemmed_str = WordNetLemmatizer().lemmatize(sample_str)\n",
    "\n",
    "print(sample_str)\n",
    "print(stemmed_str)\n",
    "print(lemmed_str)\n",
    "print()\n",
    "\n",
    "#### Takeaway: stemmer seems to cause self-referential \"I\" to register improperly as NN, noun, instead of preposition\n",
    "print([i[:3] for i in sample_str.split()])\n",
    "print([i[1] for i in nltk.pos_tag(sample_str.split())])\n",
    "print([i[1] for i in nltk.pos_tag(stemmed_str.split())])\n",
    "print([i[1] for i in nltk.pos_tag(lemmed_str.split())])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "prelim_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
